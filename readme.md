# Piotr (Peter) Sierkin
**Data Platform Engineer | Warsaw, Poland**

‚úâÔ∏è [Email](mailto:psierkin@gmail.com) / üíº [LinkedIn](https://www.linkedin.com/in/piotr-sierkin/) / üêô [GitHub](https://github.com/Santhin/)

**Professional Summary**

Data Platform Engineer with a passion for innovation and a proven track record of success in building, deploying, and maintaining modern data platforms. Expertise in Kubernetes, Docker, Terraform, DBT, and a variety of open source tools and technologies. Adept at both independent work and collaborative teamwork. Seeking a challenging position that offers opportunities for professional growth and career advancement.
##  üî® Skills
- **Languages:** Python
- **Clouds** AWS, GCP
- **Technologies:** Kubernetes, Docker, Snowflake, Airflow, DBT, Kafka (MSK/Strimzi)
- **Automation:** CICD (Gitlab/Github), FluxCD/ArgoCD, Terraform/Terragrunt

## üë©üèº‚Äçüíª Technical Experience
### Data Platform Engineer @ [GetInData](https://getindata.com/) _(May 2022 - Present)_
**Projects**
- Implemented a modern data platform using AWS, Snowflake, and Kubernetes for scalable analytics infrastructure
- Automated software delivery and integration with the data platform using FluxCD for key tools like Airflow, DataHub, Airbyte, and JupyterHub
- Developed CICD pipelines on GitLab for efficient and automated software delivery, streamlining development and deployment
- Deployed streaming infrastructure using MSK, Strimzi, Debezium, and Snowpipe streaming for real-time data processing and analytics
- Leveraged Snowflake Dynamic tables with DBT to empower data manipulation and analysis capabilities

**R&D Team**
- Data quality research and validation to optimize data pipeline effectiveness
- Defined data ingestion workflow requirements for business alignment and data governance adherence
- Integrated key data ingestion tools (Airbyte, DataHub, Airflow) into a modern data platform using Kubernetes and Terraform
- Contributed to open-source Python and Terraform projects
- Provided data infrastructure support to maintain high-quality data pipelines and optimize data processing workflows

**Technologies Used:** Python, Kubernetes, Docker, Terraform, Terragrunt, GCP, AWS, Snowflake, GitLab/Github CICD, FluxCD, MSK, Strimzi, Debezium, Snowpipe Streaming, Prometheus, Argo CD, Airbyte, DBT

### Junior Python Developer @ [EasyPartnering](https://easypartnering.pl/) _(June 2021 - April 2022)_

* Data crawling from multiple sources using Scrapy
* Data mining using SEO tools
* Finding public API's and merging with obtained data
* Responsible for planning and implementation of the serverless architecture on GCP with cloud run, cloud function, cloud build, cloud workflow, and cloud tasks
**Technologies Used:** Python(Flask, Scrapy), Docker, GCP, Github CICD

### Junior Data Engineer @ [C&F](https://candf.com/) _(November 2020 - June 2021)_

* Planned and implemented architecture for a PoC document search engine
* Cleaned and processed data from unstructured pdf/word files
* Created plots with Plotly and dashboards with Streamlit
* Supported online learning platform

**Technologies Used:** Python(Pandas, Streamlit, Spacy, NLTK, Plotly), ElasticSearch, Docker, SAP BOBJ, MSSQL

### Junior Data Scientist/Trainee @ [Bertek](https://www.bertek.eu/) _(August 2020 - November 2020)_

* Extracted unstructured data from pdf/word files
* Annotated data for NER model using Prodigy
* Crawled data with Scrapy, Selenium, and bs4

**Technologies Used:** Python (Selenium, Scrapy, BS4, Flask, Spacy), Docker, Prodigy

## üìã Projects

### Analytical Project (Engineering Thesis) @ [AirPollution](https://github.com/Santhin/air-pollution) _(August 2020 - March 2021)_

* Merged archival air pollution data from GIO≈ö with an existing database Smogoliczka
* Mapped stations with meteorological data from Synop using Dask, Coiled, and Pandas
* Conducted data cleaning, preprocessing, and explanatory data analysis using Plotly
* Performed time series prediction with Optuna for hyperparameter searching and Xgboost

**Technologies Used:** Python (Dask, Pandas, Plotly, Xgboost, Optuna), Coiled

### Academic Research Project @ [RealEstate](https://github.com/Santhin/real-estate) _(January 2021)_

* Crawled data using Scrapy, stored data in MongoDB, and deployed on Heroku
* Conducted data cleaning and preprocessing with Pandas and Spacy Morfeusz
* Created data visualizations with Plotly and matplotlib
* Conducted model learning with scikit-learn and Floydhub

**Technologies Used:** Python (Spacy, Pandas, Plotly, matplotlib, Scrapy, scikit-learn), MongoDB, Heroku

## üèÜ Accomplishments

- **Rector's Scholarship for the Best Students** @ [WWSI](https://wwsi.edu.pl/) _(2018/2019, 2020/2021)_

## üí¨ Languages

- **Polish:** Native
- **English:** B2

## üë©üèº‚Äçüéì Education

**Bachelor of Engineering**
Warsaw School of Computer Science
Thesis: Developing an evaluation and analysis model for air pollution using machine learning
Warsaw, Poland _(2017 - 2021)_
